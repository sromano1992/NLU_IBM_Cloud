{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.16.4\n",
      "  Downloading numpy-1.16.4.zip (5.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.1 MB 21.3 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: numpy\n",
      "  Building wheel for numpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for numpy: filename=numpy-1.16.4-cp38-cp38-linux_x86_64.whl size=10203404 sha256=9b9c85c9defd2163e7807714a595e4f5f0e5b80216eb4b32493154ddba46b5e6\n",
      "  Stored in directory: /tmp/wsuser/.cache/pip/wheels/a4/a2/a0/d238cbfb93ae764b3d385de800957faea46d36751def0d0557\n",
      "Successfully built numpy\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.2\n",
      "    Uninstalling numpy-1.19.2:\n",
      "      Successfully uninstalled numpy-1.19.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sparkmagic 0.18.0 requires nose, which is not installed.\n",
      "hdijupyterutils 0.18.0 requires jupyter>=1, which is not installed.\n",
      "hdijupyterutils 0.18.0 requires nose, which is not installed.\n",
      "tensorflow 2.4.4 requires flatbuffers~=1.12.0, but you have flatbuffers 20210226132247 which is incompatible.\n",
      "tensorflow 2.4.4 requires grpcio~=1.32.0, but you have grpcio 1.35.0 which is incompatible.\n",
      "tensorflow 2.4.4 requires numpy~=1.19.2, but you have numpy 1.16.4 which is incompatible.\n",
      "tensorflow 2.4.4 requires opt-einsum~=3.3.0, but you have opt-einsum 3.1.0 which is incompatible.\n",
      "snapml 1.7.6 requires numpy>=1.18.5, but you have numpy 1.16.4 which is incompatible.\n",
      "pyarrow 3.0.0 requires numpy>=1.16.6, but you have numpy 1.16.4 which is incompatible.\n",
      "pandas 1.2.4 requires numpy>=1.16.5, but you have numpy 1.16.4 which is incompatible.\n",
      "autoai-libs 1.12.13 requires numpy==1.19.2, but you have numpy 1.16.4 which is incompatible.\n",
      "astropy 4.2.1 requires numpy>=1.17, but you have numpy 1.16.4 which is incompatible.\u001b[0m\n",
      "Successfully installed numpy-1.16.4\n",
      "Collecting pandas==1.0.5\n",
      "  Downloading pandas-1.0.5-cp38-cp38-manylinux1_x86_64.whl (10.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.0 MB 22.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pandas==1.0.5) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pandas==1.0.5) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pandas==1.0.5) (1.16.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from python-dateutil>=2.6.1->pandas==1.0.5) (1.15.0)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.2.4\n",
      "    Uninstalling pandas-1.2.4:\n",
      "      Successfully uninstalled pandas-1.2.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sparkmagic 0.18.0 requires nose, which is not installed.\n",
      "hdijupyterutils 0.18.0 requires jupyter>=1, which is not installed.\n",
      "hdijupyterutils 0.18.0 requires nose, which is not installed.\n",
      "autoai-libs 1.12.13 requires numpy==1.19.2, but you have numpy 1.16.4 which is incompatible.\u001b[0m\n",
      "Successfully installed pandas-1.0.5\n",
      "Collecting ibm-watson>=5.3.0\n",
      "  Downloading ibm-watson-5.3.0.tar.gz (412 kB)\n",
      "\u001b[K     |████████████████████████████████| 412 kB 22.7 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ibm-cloud-sdk-core==3.*,>=3.3.6 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from ibm-watson>=5.3.0) (3.10.1)\n",
      "Collecting websocket-client==1.1.0\n",
      "  Downloading websocket_client-1.1.0-py2.py3-none-any.whl (68 kB)\n",
      "\u001b[K     |████████████████████████████████| 68 kB 3.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from ibm-watson>=5.3.0) (2.8.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from ibm-watson>=5.3.0) (2.25.1)\n",
      "Requirement already satisfied: PyJWT<3.0.0,>=2.0.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from ibm-cloud-sdk-core==3.*,>=3.3.6->ibm-watson>=5.3.0) (2.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from python-dateutil>=2.5.3->ibm-watson>=5.3.0) (1.15.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3.0,>=2.0->ibm-watson>=5.3.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3.0,>=2.0->ibm-watson>=5.3.0) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3.0,>=2.0->ibm-watson>=5.3.0) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3.0,>=2.0->ibm-watson>=5.3.0) (3.0.4)\n",
      "Building wheels for collected packages: ibm-watson\n",
      "  Building wheel for ibm-watson (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ibm-watson: filename=ibm_watson-5.3.0-py3-none-any.whl size=408872 sha256=4e97107ab1fc4991c3067539ffba73914bb4906393c01863ac0782ac1293c7f5\n",
      "  Stored in directory: /tmp/wsuser/.cache/pip/wheels/79/7c/1e/3fc8483af029cd8cb8c803eeaf282cbeb60724130d9dca4b83\n",
      "Successfully built ibm-watson\n",
      "Installing collected packages: websocket-client, ibm-watson\n",
      "Successfully installed ibm-watson-5.3.0 websocket-client-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade numpy==1.16.4\n",
    "!pip install --upgrade pandas==1.0.5\n",
    "!pip install --upgrade \"ibm-watson>=5.3.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "\n",
    "def create_download_link( df, title = \"Download CSV file\", filename = \"data.csv\"):\n",
    "    csv = df.to_csv()\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your input here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_WATSON_NLU_APIKEY = '***'\n",
    "_WATSON_NLU_URL = 'https://api.eu-gb.natural-language-understanding.watson.cloud.ibm.com'    #more details here - https://cloud.ibm.com/apidocs/natural-language-understanding?code=python#endpoint-cloud\n",
    "                  \n",
    "keyword = ['delta']\n",
    "site = 'https://www.who.int/news/item/28-11-2021-update-on-omicron'    #website to analyze - english website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watson NLU interaction here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from ibm_watson import NaturalLanguageUnderstandingV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "from ibm_watson.natural_language_understanding_v1 import Features, SentimentOptions, EmotionOptions, MetadataOptions\n",
    "\n",
    "                                          \n",
    "authenticator = IAMAuthenticator(_WATSON_NLU_APIKEY)\n",
    "natural_language_understanding = NaturalLanguageUnderstandingV1(\n",
    "    version='2021-08-01',\n",
    "    authenticator=authenticator\n",
    ")\n",
    "\n",
    "natural_language_understanding.set_service_url(_WATSON_NLU_URL)\n",
    "\n",
    "from ibm_watson import ApiException\n",
    "try:\n",
    "    response = natural_language_understanding.analyze(\n",
    "        url=site,\n",
    "    features=Features(metadata=MetadataOptions(), sentiment=SentimentOptions(document=True, targets=keyword), emotion=EmotionOptions(document=True))).get_result()\n",
    "\n",
    "    out_string = json.dumps(response, indent=2)\n",
    "    # build CSV\n",
    "    # site, keyword, etc.\n",
    "\n",
    "    import pandas as pd\n",
    "    out_json = json.loads(out_string)    #dict\n",
    "    #print(out_string)\n",
    "except ApiException as ex:\n",
    "    print(\"Method failed with status code \" + str(ex.code) + \": \" + ex.message)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate csv and data download link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a download=\"data_1642689889_delta.csv\" href=\"data:text/csv;base64,c2l0ZSx0aXRsZSxwdWJsaWNhdGlvbl9kYXRlLGtleXdvcmQsc2VudGltZW50LnRhcmdldC50ZXh0LHNlbnRpbWVudC50YXJnZXQuc2NvcmUsc2VudGltZW50LnRhcmdldC5sYWJlbCxzZW50aW1lbnQuZG9jdW1lbnQuc2NvcmUsc2VudGltZW50LmRvY3VtZW50LmxhYmVsLGVtb3Rpb24uZG9jdW1lbnQuZW1vdGlvbi5zYWRuZXNzLGVtb3Rpb24uZG9jdW1lbnQuZW1vdGlvbi5qb3ksZW1vdGlvbi5kb2N1bWVudC5lbW90aW9uLmZlYXIsZW1vdGlvbi5kb2N1bWVudC5lbW90aW9uLmRpc2d1c3QsZW1vdGlvbi5kb2N1bWVudC5lbW90aW9uLmFuZ2VyCmh0dHBzOi8vd3d3Lndoby5pbnQvbmV3cy9pdGVtLzI4LTExLTIwMjEtdXBkYXRlLW9uLW9taWNyb24sVXBkYXRlIG9uIE9taWNyb24sMjAyMS0xMS0yOFQwMDowMDowMCxkZWx0YSxkZWx0YSwtMC41NzgxMDcsbmVnYXRpdmUsMC4zMjQwODUscG9zaXRpdmUsMC4xOTYzNjIsMC4xNzE5MywwLjEzMjY2MSwwLjA2NjcwNCwwLjA1NjU2Mwo=\" target=\"_blank\">Download CSV file</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'site':site, 'title': out_json['metadata']['title'], 'publication_date': out_json['metadata']['publication_date'], 'keyword': keyword,\n",
    "        'sentiment.target.text': out_json['sentiment']['targets'][0]['text'], 'sentiment.target.score': out_json['sentiment']['targets'][0]['score'], 'sentiment.target.label': out_json['sentiment']['targets'][0]['label'],\n",
    "        'sentiment.document.score': out_json['sentiment']['document']['score'], 'sentiment.document.label': out_json['sentiment']['document']['label'],\n",
    "        'emotion.document.emotion.sadness': out_json['emotion']['document']['emotion']['sadness'],'emotion.document.emotion.joy': out_json['emotion']['document']['emotion']['joy'],\n",
    "        'emotion.document.emotion.fear': out_json['emotion']['document']['emotion']['fear'],'emotion.document.emotion.disgust': out_json['emotion']['document']['emotion']['disgust'],\n",
    "        'emotion.document.emotion.anger': out_json['emotion']['document']['emotion']['anger']\n",
    "       }\n",
    "  \n",
    "# Creates pandas DataFrame.  \n",
    "df = pd.DataFrame(data)\n",
    "df.set_index('site', inplace=True)\n",
    "  \n",
    "# print the data  \n",
    "df\n",
    "\n",
    "# generate download link\n",
    "import time\n",
    "epoch_time = int(time.time())\n",
    "create_download_link(df, filename='data_' + str(epoch_time) + '_' + keyword[0] + '.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
